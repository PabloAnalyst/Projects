{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "bbe2bc2a",
      "cell_type": "code",
      "source": "import pandas as pd\nimport os\nimport glob\n\n# Load the files\nbase_path = r\"C:\\Analysis Files\"\ndf1 = pd.read_excel(f\"{base_path}\\A1.xlsx\")\ndf2 = pd.read_csv(f\"{base_path}\\A2.csv\", encoding='latin1')\ndf3 = pd.read_csv(f\"{base_path}\\A3.csv\", encoding='latin1', delimiter=';')\ndf4 = pd.read_csv(f\"{base_path}\\A4\", encoding='latin1')\ndf5 = pd.read_excel(f\"{base_path}\\A5.xlsx\")\ndf6 = pd.read_csv(f\"{base_path}\\\\A6\", encoding='latin1')\n\n# Verify that DataFrames were loaded correctly\nprint(\"a1:\\n\", allmdr.head())\nprint(\"a2:\\n\", allraa.head())\nprint(\"a3:\\n\", ldr.head())\nprint(\"a4:\\n\", licenses.head())\nprint(\"a5:\\n\", mrs.head())\nprint(\"a6:\\n\", variants.head())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c00f9fd2",
      "cell_type": "code",
      "source": "# Load multiple files in a single dataframe\nfolder_path = r'C:\\Bulk Files'\ncsv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n# Create a list to store DataFrames\ndataframes = []\n\n# Read each CSV file and add it to the list of DataFrames\nfor file in csv_files:\n    try:\n        df = pd.read_csv(file, encoding='ISO-8859-1')  # Change encoding here if necessary\n        df['Column1'] = os.path.basename(file).replace('.csv', '')  # Rename the column and remove .csv\n        dataframes.append(df)\n    except Exception as e:\n        print(f\"Error reading file {file}: {e}\")\nbulk_files = pd.concat(dataframes, ignore_index=True)\nprint(bulk_files)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bf787fe9",
      "cell_type": "code",
      "source": "#Select only the variables that are necessary for the analysis\ncolumns_to_keep = [\n    'c4', 'c6', 'c8', 'c2', 'c6', \n    'c22', 'c12']\ndf1 = df1[columns_to_keep]\n##\ncolumns_to_keep = [\n    'c5', 'c7', 'c1', 'c12', 'c15', \n    'c15', 'c8']\ndf2 = df2[columns_to_keep]\n\n##.........",
      "metadata": {},
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "f472ba59-18fa-4416-90b4-9b85045346fa",
      "cell_type": "code",
      "source": "# Save each DataFrame as a CSV file\ndataframes = {\n    'df1': df1,\n    'df2': df2,\n    'df3': df3,\n    'df4': df4,\n    'df5': df5,\n    'df6': df6,\n    'df7': df7,\n}\n\npath = r'C:\\Result'\n\nfor name, df in dataframes.items():\n    df.to_csv(f\"{path}\\\\{name}.csv\", index=False)\n\nprint(\"CSV files saved successfully.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a0cd1474-6035-40a3-8779-ff3fdfafe4ed",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}